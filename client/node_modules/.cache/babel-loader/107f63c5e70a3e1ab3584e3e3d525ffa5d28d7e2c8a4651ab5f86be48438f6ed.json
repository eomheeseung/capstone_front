{"ast":null,"code":"\"use strict\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n      label: 0,\n      sent: function () {\n        if (t[0] & 1) throw t[1];\n        return t[1];\n      },\n      trys: [],\n      ops: []\n    },\n    f,\n    y,\n    t,\n    g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n    while (g && (g = 0, op[0] && (_ = 0)), _) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n        case 7:\n          op = _.ops.pop();\n          _.trys.pop();\n          continue;\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n            _.ops.push(op);\n            break;\n          }\n          if (t[2]) _.ops.pop();\n          _.trys.pop();\n          continue;\n      }\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.tensorBoard = exports.TensorBoardCallback = exports.getDisplayDecimalPlaces = exports.getSuccinctNumberDisplay = exports.ProgbarLogger = exports.progressBarHelper = void 0;\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar path = require(\"path\");\nvar ProgressBar = require(\"progress\");\nvar tensorboard_1 = require(\"./tensorboard\");\n// A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\nexports.progressBarHelper = {\n  ProgressBar: ProgressBar,\n  log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\nvar ProgbarLogger = /** @class */function (_super) {\n  __extends(ProgbarLogger, _super);\n  /**\n   * Construtor of LoggingCallback.\n   */\n  function ProgbarLogger() {\n    var _this = _super.call(this, {\n      onTrainBegin: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var samples, batchSize, steps;\n          return __generator(this, function (_a) {\n            samples = this.params.samples;\n            batchSize = this.params.batchSize;\n            steps = this.params.steps;\n            if (samples != null || steps != null) {\n              this.numTrainBatchesPerEpoch = samples != null ? Math.ceil(samples / batchSize) : steps;\n            } else {\n              // Undetermined number of batches per epoch, e.g., due to\n              // `fitDataset()` without `batchesPerEpoch`.\n              this.numTrainBatchesPerEpoch = 0;\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onEpochBegin: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            exports.progressBarHelper.log(\"Epoch \".concat(epoch + 1, \" / \").concat(this.params.epochs));\n            this.currentEpochBegin = tfjs_1.util.now();\n            this.epochDurationMillis = null;\n            this.usPerStep = null;\n            this.batchesInLatestEpoch = 0;\n            this.terminalWidth = process.stderr.columns;\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var maxMetricsStringLength, tickTokens;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                this.batchesInLatestEpoch++;\n                if (batch === 0) {\n                  this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                    width: Math.floor(0.5 * this.terminalWidth),\n                    total: this.numTrainBatchesPerEpoch + 1,\n                    head: \">\",\n                    renderThrottle: this.RENDER_THROTTLE_MS\n                  });\n                }\n                maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                tickTokens = {\n                  placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                };\n                if (this.numTrainBatchesPerEpoch === 0) {\n                  // Undetermined number of batches per epoch.\n                  this.progressBar.tick(0, tickTokens);\n                } else {\n                  this.progressBar.tick(tickTokens);\n                }\n                return [4 /*yield*/, (0, tfjs_1.nextFrame)()];\n              case 1:\n                _a.sent();\n                if (batch === this.numTrainBatchesPerEpoch - 1) {\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.params.samples != null ? this.epochDurationMillis / this.params.samples * 1e3 : this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n                return [2 /*return*/];\n            }\n          });\n        });\n      },\n\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var lossesAndMetricsString;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                if (this.epochDurationMillis == null) {\n                  // In cases where the number of batches per epoch is not determined,\n                  // the calculation of the per-step duration is done at the end of the\n                  // epoch. N.B., this includes the time spent on validation.\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n                this.progressBar.tick({\n                  placeholderForLossesAndMetrics: ''\n                });\n                lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                exports.progressBarHelper.log(\"\".concat(this.epochDurationMillis.toFixed(0), \"ms \") + \"\".concat(this.usPerStep.toFixed(0), \"us/step - \") + \"\".concat(lossesAndMetricsString));\n                return [4 /*yield*/, (0, tfjs_1.nextFrame)()];\n              case 1:\n                _a.sent();\n                return [2 /*return*/];\n            }\n          });\n        });\n      }\n    }) || this;\n    _this.RENDER_THROTTLE_MS = 50;\n    return _this;\n  }\n  ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n    var metricsContent = '';\n    var keys = Object.keys(logs).sort();\n    for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n      var key = keys_1[_i];\n      if (this.isFieldRelevant(key)) {\n        var value = logs[key];\n        metricsContent += \"\".concat(key, \"=\").concat(getSuccinctNumberDisplay(value), \" \");\n      }\n    }\n    if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n      // Cut off metrics strings that are too long to avoid new lines being\n      // constantly created.\n      metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n    }\n    return metricsContent;\n  };\n  ProgbarLogger.prototype.isFieldRelevant = function (key) {\n    return key !== 'batch' && key !== 'size';\n  };\n  return ProgbarLogger;\n}(tfjs_1.CustomCallback);\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\nfunction getSuccinctNumberDisplay(x) {\n  var decimalPlaces = getDisplayDecimalPlaces(x);\n  return decimalPlaces > MAX_NUM_DECIMAL_PLACES ? x.toExponential(BASE_NUM_DIGITS) : x.toFixed(decimalPlaces);\n}\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\nfunction getDisplayDecimalPlaces(x) {\n  if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n    return BASE_NUM_DIGITS;\n  } else {\n    return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n  }\n}\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\nvar TensorBoardCallback = /** @class */function (_super) {\n  __extends(TensorBoardCallback, _super);\n  function TensorBoardCallback(logdir, args) {\n    if (logdir === void 0) {\n      logdir = './logs';\n    }\n    var _this = _super.call(this, {\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.batchesSeen++;\n            if (this.args.updateFreq !== 'epoch') {\n              this.logMetrics(logs, 'batch_', this.batchesSeen);\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.logMetrics(logs, 'epoch_', epoch + 1);\n            if (this.args.histogramFreq > 0 && epoch % this.args.histogramFreq === 0) {\n              this.logWeights(epoch);\n            }\n            return [2 /*return*/];\n          });\n        });\n      },\n\n      onTrainEnd: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            if (this.trainWriter != null) {\n              this.trainWriter.flush();\n            }\n            if (this.valWriter != null) {\n              this.valWriter.flush();\n            }\n            return [2 /*return*/];\n          });\n        });\n      }\n    }) || this;\n    _this.logdir = logdir;\n    _this.model = null;\n    _this.args = args == null ? {} : args;\n    if (_this.args.updateFreq == null) {\n      _this.args.updateFreq = 'epoch';\n    }\n    tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () {\n      return \"Expected updateFreq to be 'batch' or 'epoch', but got \" + \"\".concat(_this.args.updateFreq);\n    });\n    if (_this.args.histogramFreq == null) {\n      _this.args.histogramFreq = 0;\n    }\n    tfjs_1.util.assert(Number.isInteger(_this.args.histogramFreq) && _this.args.histogramFreq >= 0, function () {\n      return \"Expected histogramFreq to be a positive integer, but got \" + \"\".concat(_this.args.histogramFreq);\n    });\n    _this.batchesSeen = 0;\n    return _this;\n  }\n  TensorBoardCallback.prototype.setModel = function (model) {\n    // This method is inherited from BaseCallback. To avoid cyclical imports,\n    // that class uses Container instead of LayersModel, and uses a run-time\n    // check to make sure the model is a LayersModel.\n    // Since this subclass isn't imported by tfjs-layers, we can safely use type\n    // the parameter as a LayersModel.\n    this.model = model;\n  };\n  TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n    for (var key in logs) {\n      if (key === 'batch' || key === 'size' || key === 'num_steps') {\n        continue;\n      }\n      var VAL_PREFIX = 'val_';\n      if (key.startsWith(VAL_PREFIX)) {\n        this.ensureValWriterCreated();\n        var scalarName = prefix + key.slice(VAL_PREFIX.length);\n        this.valWriter.scalar(scalarName, logs[key], step);\n      } else {\n        this.ensureTrainWriterCreated();\n        this.trainWriter.scalar(\"\".concat(prefix).concat(key), logs[key], step);\n      }\n    }\n  };\n  TensorBoardCallback.prototype.logWeights = function (step) {\n    for (var _i = 0, _a = this.model.weights; _i < _a.length; _i++) {\n      var weights = _a[_i];\n      this.trainWriter.histogram(weights.name, weights.read(), step);\n    }\n  };\n  TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n    this.trainWriter = (0, tensorboard_1.summaryFileWriter)(path.join(this.logdir, 'train'));\n  };\n  TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n    this.valWriter = (0, tensorboard_1.summaryFileWriter)(path.join(this.logdir, 'val'));\n  };\n  return TensorBoardCallback;\n}(tfjs_1.CustomCallback);\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n *\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\nfunction tensorBoard(logdir, args) {\n  if (logdir === void 0) {\n    logdir = './logs';\n  }\n  return new TensorBoardCallback(logdir, args);\n}\nexports.tensorBoard = tensorBoard;","map":{"version":3,"names":["__extends","extendStatics","d","b","Object","setPrototypeOf","__proto__","Array","p","prototype","hasOwnProperty","call","TypeError","String","__","constructor","create","__awaiter","thisArg","_arguments","P","generator","adopt","value","resolve","Promise","reject","fulfilled","step","next","e","rejected","result","done","then","apply","__generator","body","_","label","sent","t","trys","ops","f","y","g","verb","Symbol","iterator","n","v","op","pop","length","push","defineProperty","exports","tensorBoard","TensorBoardCallback","getDisplayDecimalPlaces","getSuccinctNumberDisplay","ProgbarLogger","progressBarHelper","tfjs_1","require","path","ProgressBar","tensorboard_1","log","console","_super","_this","onTrainBegin","logs","samples","batchSize","steps","_a","params","numTrainBatchesPerEpoch","Math","ceil","onEpochBegin","epoch","concat","epochs","currentEpochBegin","util","now","epochDurationMillis","usPerStep","batchesInLatestEpoch","terminalWidth","process","stderr","columns","onBatchEnd","batch","maxMetricsStringLength","tickTokens","progressBar","width","floor","total","head","renderThrottle","RENDER_THROTTLE_MS","placeholderForLossesAndMetrics","formatLogsAsMetricsContent","tick","nextFrame","onEpochEnd","lossesAndMetricsString","toFixed","maxMetricsLength","metricsContent","keys","sort","_i","keys_1","key","isFieldRelevant","slice","CustomCallback","BASE_NUM_DIGITS","MAX_NUM_DECIMAL_PLACES","x","decimalPlaces","toExponential","Number","isFinite","log10","abs","logdir","args","batchesSeen","updateFreq","logMetrics","histogramFreq","logWeights","onTrainEnd","trainWriter","flush","valWriter","model","assert","indexOf","isInteger","setModel","prefix","VAL_PREFIX","startsWith","ensureValWriterCreated","scalarName","scalar","ensureTrainWriterCreated","weights","histogram","name","read","summaryFileWriter","join"],"sources":["C:/Users/paete/CapstonPro/nftmusicProtoCopy/client/node_modules/@tensorflow/tfjs-node/dist/callbacks.js"],"sourcesContent":["\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (g && (g = 0, op[0] && (_ = 0)), _) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.tensorBoard = exports.TensorBoardCallback = exports.getDisplayDecimalPlaces = exports.getSuccinctNumberDisplay = exports.ProgbarLogger = exports.progressBarHelper = void 0;\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar path = require(\"path\");\nvar ProgressBar = require(\"progress\");\nvar tensorboard_1 = require(\"./tensorboard\");\n// A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\nexports.progressBarHelper = {\n    ProgressBar: ProgressBar,\n    log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\nvar ProgbarLogger = /** @class */ (function (_super) {\n    __extends(ProgbarLogger, _super);\n    /**\n     * Construtor of LoggingCallback.\n     */\n    function ProgbarLogger() {\n        var _this = _super.call(this, {\n            onTrainBegin: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                var samples, batchSize, steps;\n                return __generator(this, function (_a) {\n                    samples = this.params.samples;\n                    batchSize = this.params.batchSize;\n                    steps = this.params.steps;\n                    if (samples != null || steps != null) {\n                        this.numTrainBatchesPerEpoch =\n                            samples != null ? Math.ceil(samples / batchSize) : steps;\n                    }\n                    else {\n                        // Undetermined number of batches per epoch, e.g., due to\n                        // `fitDataset()` without `batchesPerEpoch`.\n                        this.numTrainBatchesPerEpoch = 0;\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochBegin: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    exports.progressBarHelper.log(\"Epoch \".concat(epoch + 1, \" / \").concat(this.params.epochs));\n                    this.currentEpochBegin = tfjs_1.util.now();\n                    this.epochDurationMillis = null;\n                    this.usPerStep = null;\n                    this.batchesInLatestEpoch = 0;\n                    this.terminalWidth = process.stderr.columns;\n                    return [2 /*return*/];\n                });\n            }); },\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var maxMetricsStringLength, tickTokens;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            this.batchesInLatestEpoch++;\n                            if (batch === 0) {\n                                this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                                    width: Math.floor(0.5 * this.terminalWidth),\n                                    total: this.numTrainBatchesPerEpoch + 1,\n                                    head: \">\",\n                                    renderThrottle: this.RENDER_THROTTLE_MS\n                                });\n                            }\n                            maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                            tickTokens = {\n                                placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                            };\n                            if (this.numTrainBatchesPerEpoch === 0) {\n                                // Undetermined number of batches per epoch.\n                                this.progressBar.tick(0, tickTokens);\n                            }\n                            else {\n                                this.progressBar.tick(tickTokens);\n                            }\n                            return [4 /*yield*/, (0, tfjs_1.nextFrame)()];\n                        case 1:\n                            _a.sent();\n                            if (batch === this.numTrainBatchesPerEpoch - 1) {\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep = this.params.samples != null ?\n                                    this.epochDurationMillis / this.params.samples * 1e3 :\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var lossesAndMetricsString;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            if (this.epochDurationMillis == null) {\n                                // In cases where the number of batches per epoch is not determined,\n                                // the calculation of the per-step duration is done at the end of the\n                                // epoch. N.B., this includes the time spent on validation.\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep =\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            this.progressBar.tick({ placeholderForLossesAndMetrics: '' });\n                            lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                            exports.progressBarHelper.log(\"\".concat(this.epochDurationMillis.toFixed(0), \"ms \") +\n                                \"\".concat(this.usPerStep.toFixed(0), \"us/step - \") +\n                                \"\".concat(lossesAndMetricsString));\n                            return [4 /*yield*/, (0, tfjs_1.nextFrame)()];\n                        case 1:\n                            _a.sent();\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n        }) || this;\n        _this.RENDER_THROTTLE_MS = 50;\n        return _this;\n    }\n    ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n        var metricsContent = '';\n        var keys = Object.keys(logs).sort();\n        for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n            var key = keys_1[_i];\n            if (this.isFieldRelevant(key)) {\n                var value = logs[key];\n                metricsContent += \"\".concat(key, \"=\").concat(getSuccinctNumberDisplay(value), \" \");\n            }\n        }\n        if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n            // Cut off metrics strings that are too long to avoid new lines being\n            // constantly created.\n            metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n        }\n        return metricsContent;\n    };\n    ProgbarLogger.prototype.isFieldRelevant = function (key) {\n        return key !== 'batch' && key !== 'size';\n    };\n    return ProgbarLogger;\n}(tfjs_1.CustomCallback));\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\nfunction getSuccinctNumberDisplay(x) {\n    var decimalPlaces = getDisplayDecimalPlaces(x);\n    return decimalPlaces > MAX_NUM_DECIMAL_PLACES ?\n        x.toExponential(BASE_NUM_DIGITS) :\n        x.toFixed(decimalPlaces);\n}\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\nfunction getDisplayDecimalPlaces(x) {\n    if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n        return BASE_NUM_DIGITS;\n    }\n    else {\n        return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n    }\n}\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\nvar TensorBoardCallback = /** @class */ (function (_super) {\n    __extends(TensorBoardCallback, _super);\n    function TensorBoardCallback(logdir, args) {\n        if (logdir === void 0) { logdir = './logs'; }\n        var _this = _super.call(this, {\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.batchesSeen++;\n                    if (this.args.updateFreq !== 'epoch') {\n                        this.logMetrics(logs, 'batch_', this.batchesSeen);\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.logMetrics(logs, 'epoch_', epoch + 1);\n                    if (this.args.histogramFreq > 0 &&\n                        epoch % this.args.histogramFreq === 0) {\n                        this.logWeights(epoch);\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onTrainEnd: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    if (this.trainWriter != null) {\n                        this.trainWriter.flush();\n                    }\n                    if (this.valWriter != null) {\n                        this.valWriter.flush();\n                    }\n                    return [2 /*return*/];\n                });\n            }); }\n        }) || this;\n        _this.logdir = logdir;\n        _this.model = null;\n        _this.args = args == null ? {} : args;\n        if (_this.args.updateFreq == null) {\n            _this.args.updateFreq = 'epoch';\n        }\n        tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () { return \"Expected updateFreq to be 'batch' or 'epoch', but got \" +\n            \"\".concat(_this.args.updateFreq); });\n        if (_this.args.histogramFreq == null) {\n            _this.args.histogramFreq = 0;\n        }\n        tfjs_1.util.assert(Number.isInteger(_this.args.histogramFreq) &&\n            _this.args.histogramFreq >= 0, function () { return \"Expected histogramFreq to be a positive integer, but got \" +\n            \"\".concat(_this.args.histogramFreq); });\n        _this.batchesSeen = 0;\n        return _this;\n    }\n    TensorBoardCallback.prototype.setModel = function (model) {\n        // This method is inherited from BaseCallback. To avoid cyclical imports,\n        // that class uses Container instead of LayersModel, and uses a run-time\n        // check to make sure the model is a LayersModel.\n        // Since this subclass isn't imported by tfjs-layers, we can safely use type\n        // the parameter as a LayersModel.\n        this.model = model;\n    };\n    TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n        for (var key in logs) {\n            if (key === 'batch' || key === 'size' || key === 'num_steps') {\n                continue;\n            }\n            var VAL_PREFIX = 'val_';\n            if (key.startsWith(VAL_PREFIX)) {\n                this.ensureValWriterCreated();\n                var scalarName = prefix + key.slice(VAL_PREFIX.length);\n                this.valWriter.scalar(scalarName, logs[key], step);\n            }\n            else {\n                this.ensureTrainWriterCreated();\n                this.trainWriter.scalar(\"\".concat(prefix).concat(key), logs[key], step);\n            }\n        }\n    };\n    TensorBoardCallback.prototype.logWeights = function (step) {\n        for (var _i = 0, _a = this.model.weights; _i < _a.length; _i++) {\n            var weights = _a[_i];\n            this.trainWriter.histogram(weights.name, weights.read(), step);\n        }\n    };\n    TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n        this.trainWriter = (0, tensorboard_1.summaryFileWriter)(path.join(this.logdir, 'train'));\n    };\n    TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n        this.valWriter = (0, tensorboard_1.summaryFileWriter)(path.join(this.logdir, 'val'));\n    };\n    return TensorBoardCallback;\n}(tfjs_1.CustomCallback));\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n *\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\nfunction tensorBoard(logdir, args) {\n    if (logdir === void 0) { logdir = './logs'; }\n    return new TensorBoardCallback(logdir, args);\n}\nexports.tensorBoard = tensorBoard;\n"],"mappings":"AAAA,YAAY;;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIA,SAAS,GAAI,IAAI,IAAI,IAAI,CAACA,SAAS,IAAM,YAAY;EACrD,IAAIC,aAAa,GAAG,UAAUC,CAAC,EAAEC,CAAC,EAAE;IAChCF,aAAa,GAAGG,MAAM,CAACC,cAAc,IAChC;MAAEC,SAAS,EAAE;IAAG,CAAC,YAAYC,KAAK,IAAI,UAAUL,CAAC,EAAEC,CAAC,EAAE;MAAED,CAAC,CAACI,SAAS,GAAGH,CAAC;IAAE,CAAE,IAC5E,UAAUD,CAAC,EAAEC,CAAC,EAAE;MAAE,KAAK,IAAIK,CAAC,IAAIL,CAAC,EAAE,IAAIC,MAAM,CAACK,SAAS,CAACC,cAAc,CAACC,IAAI,CAACR,CAAC,EAAEK,CAAC,CAAC,EAAEN,CAAC,CAACM,CAAC,CAAC,GAAGL,CAAC,CAACK,CAAC,CAAC;IAAE,CAAC;IACrG,OAAOP,aAAa,CAACC,CAAC,EAAEC,CAAC,CAAC;EAC9B,CAAC;EACD,OAAO,UAAUD,CAAC,EAAEC,CAAC,EAAE;IACnB,IAAI,OAAOA,CAAC,KAAK,UAAU,IAAIA,CAAC,KAAK,IAAI,EACrC,MAAM,IAAIS,SAAS,CAAC,sBAAsB,GAAGC,MAAM,CAACV,CAAC,CAAC,GAAG,+BAA+B,CAAC;IAC7FF,aAAa,CAACC,CAAC,EAAEC,CAAC,CAAC;IACnB,SAASW,EAAE,GAAG;MAAE,IAAI,CAACC,WAAW,GAAGb,CAAC;IAAE;IACtCA,CAAC,CAACO,SAAS,GAAGN,CAAC,KAAK,IAAI,GAAGC,MAAM,CAACY,MAAM,CAACb,CAAC,CAAC,IAAIW,EAAE,CAACL,SAAS,GAAGN,CAAC,CAACM,SAAS,EAAE,IAAIK,EAAE,EAAE,CAAC;EACxF,CAAC;AACL,CAAC,EAAG;AACJ,IAAIG,SAAS,GAAI,IAAI,IAAI,IAAI,CAACA,SAAS,IAAK,UAAUC,OAAO,EAAEC,UAAU,EAAEC,CAAC,EAAEC,SAAS,EAAE;EACrF,SAASC,KAAK,CAACC,KAAK,EAAE;IAAE,OAAOA,KAAK,YAAYH,CAAC,GAAGG,KAAK,GAAG,IAAIH,CAAC,CAAC,UAAUI,OAAO,EAAE;MAAEA,OAAO,CAACD,KAAK,CAAC;IAAE,CAAC,CAAC;EAAE;EAC3G,OAAO,KAAKH,CAAC,KAAKA,CAAC,GAAGK,OAAO,CAAC,EAAE,UAAUD,OAAO,EAAEE,MAAM,EAAE;IACvD,SAASC,SAAS,CAACJ,KAAK,EAAE;MAAE,IAAI;QAAEK,IAAI,CAACP,SAAS,CAACQ,IAAI,CAACN,KAAK,CAAC,CAAC;MAAE,CAAC,CAAC,OAAOO,CAAC,EAAE;QAAEJ,MAAM,CAACI,CAAC,CAAC;MAAE;IAAE;IAC1F,SAASC,QAAQ,CAACR,KAAK,EAAE;MAAE,IAAI;QAAEK,IAAI,CAACP,SAAS,CAAC,OAAO,CAAC,CAACE,KAAK,CAAC,CAAC;MAAE,CAAC,CAAC,OAAOO,CAAC,EAAE;QAAEJ,MAAM,CAACI,CAAC,CAAC;MAAE;IAAE;IAC7F,SAASF,IAAI,CAACI,MAAM,EAAE;MAAEA,MAAM,CAACC,IAAI,GAAGT,OAAO,CAACQ,MAAM,CAACT,KAAK,CAAC,GAAGD,KAAK,CAACU,MAAM,CAACT,KAAK,CAAC,CAACW,IAAI,CAACP,SAAS,EAAEI,QAAQ,CAAC;IAAE;IAC7GH,IAAI,CAAC,CAACP,SAAS,GAAGA,SAAS,CAACc,KAAK,CAACjB,OAAO,EAAEC,UAAU,IAAI,EAAE,CAAC,EAAEU,IAAI,EAAE,CAAC;EACzE,CAAC,CAAC;AACN,CAAC;AACD,IAAIO,WAAW,GAAI,IAAI,IAAI,IAAI,CAACA,WAAW,IAAK,UAAUlB,OAAO,EAAEmB,IAAI,EAAE;EACrE,IAAIC,CAAC,GAAG;MAAEC,KAAK,EAAE,CAAC;MAAEC,IAAI,EAAE,YAAW;QAAE,IAAIC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,MAAMA,CAAC,CAAC,CAAC,CAAC;QAAE,OAAOA,CAAC,CAAC,CAAC,CAAC;MAAE,CAAC;MAAEC,IAAI,EAAE,EAAE;MAAEC,GAAG,EAAE;IAAG,CAAC;IAAEC,CAAC;IAAEC,CAAC;IAAEJ,CAAC;IAAEK,CAAC;EAChH,OAAOA,CAAC,GAAG;IAAEjB,IAAI,EAAEkB,IAAI,CAAC,CAAC,CAAC;IAAE,OAAO,EAAEA,IAAI,CAAC,CAAC,CAAC;IAAE,QAAQ,EAAEA,IAAI,CAAC,CAAC;EAAE,CAAC,EAAE,OAAOC,MAAM,KAAK,UAAU,KAAKF,CAAC,CAACE,MAAM,CAACC,QAAQ,CAAC,GAAG,YAAW;IAAE,OAAO,IAAI;EAAE,CAAC,CAAC,EAAEH,CAAC;EACxJ,SAASC,IAAI,CAACG,CAAC,EAAE;IAAE,OAAO,UAAUC,CAAC,EAAE;MAAE,OAAOvB,IAAI,CAAC,CAACsB,CAAC,EAAEC,CAAC,CAAC,CAAC;IAAE,CAAC;EAAE;EACjE,SAASvB,IAAI,CAACwB,EAAE,EAAE;IACd,IAAIR,CAAC,EAAE,MAAM,IAAIhC,SAAS,CAAC,iCAAiC,CAAC;IAC7D,OAAOkC,CAAC,KAAKA,CAAC,GAAG,CAAC,EAAEM,EAAE,CAAC,CAAC,CAAC,KAAKd,CAAC,GAAG,CAAC,CAAC,CAAC,EAAEA,CAAC,EAAE,IAAI;MAC1C,IAAIM,CAAC,GAAG,CAAC,EAAEC,CAAC,KAAKJ,CAAC,GAAGW,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,GAAGP,CAAC,CAAC,QAAQ,CAAC,GAAGO,EAAE,CAAC,CAAC,CAAC,GAAGP,CAAC,CAAC,OAAO,CAAC,KAAK,CAACJ,CAAC,GAAGI,CAAC,CAAC,QAAQ,CAAC,KAAKJ,CAAC,CAAC9B,IAAI,CAACkC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAGA,CAAC,CAAChB,IAAI,CAAC,IAAI,CAAC,CAACY,CAAC,GAAGA,CAAC,CAAC9B,IAAI,CAACkC,CAAC,EAAEO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAEnB,IAAI,EAAE,OAAOQ,CAAC;MAC5J,IAAII,CAAC,GAAG,CAAC,EAAEJ,CAAC,EAAEW,EAAE,GAAG,CAACA,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAEX,CAAC,CAAClB,KAAK,CAAC;MACvC,QAAQ6B,EAAE,CAAC,CAAC,CAAC;QACT,KAAK,CAAC;QAAE,KAAK,CAAC;UAAEX,CAAC,GAAGW,EAAE;UAAE;QACxB,KAAK,CAAC;UAAEd,CAAC,CAACC,KAAK,EAAE;UAAE,OAAO;YAAEhB,KAAK,EAAE6B,EAAE,CAAC,CAAC,CAAC;YAAEnB,IAAI,EAAE;UAAM,CAAC;QACvD,KAAK,CAAC;UAAEK,CAAC,CAACC,KAAK,EAAE;UAAEM,CAAC,GAAGO,EAAE,CAAC,CAAC,CAAC;UAAEA,EAAE,GAAG,CAAC,CAAC,CAAC;UAAE;QACxC,KAAK,CAAC;UAAEA,EAAE,GAAGd,CAAC,CAACK,GAAG,CAACU,GAAG,EAAE;UAAEf,CAAC,CAACI,IAAI,CAACW,GAAG,EAAE;UAAE;QACxC;UACI,IAAI,EAAEZ,CAAC,GAAGH,CAAC,CAACI,IAAI,EAAED,CAAC,GAAGA,CAAC,CAACa,MAAM,GAAG,CAAC,IAAIb,CAAC,CAACA,CAAC,CAACa,MAAM,GAAG,CAAC,CAAC,CAAC,KAAKF,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,IAAIA,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;YAAEd,CAAC,GAAG,CAAC;YAAE;UAAU;UAC3G,IAAIc,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAACX,CAAC,IAAKW,EAAE,CAAC,CAAC,CAAC,GAAGX,CAAC,CAAC,CAAC,CAAC,IAAIW,EAAE,CAAC,CAAC,CAAC,GAAGX,CAAC,CAAC,CAAC,CAAE,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGa,EAAE,CAAC,CAAC,CAAC;YAAE;UAAO;UACrF,IAAIA,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,IAAId,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC;YAAEA,CAAC,GAAGW,EAAE;YAAE;UAAO;UACpE,IAAIX,CAAC,IAAIH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC,EAAE;YAAEH,CAAC,CAACC,KAAK,GAAGE,CAAC,CAAC,CAAC,CAAC;YAAEH,CAAC,CAACK,GAAG,CAACY,IAAI,CAACH,EAAE,CAAC;YAAE;UAAO;UAClE,IAAIX,CAAC,CAAC,CAAC,CAAC,EAAEH,CAAC,CAACK,GAAG,CAACU,GAAG,EAAE;UACrBf,CAAC,CAACI,IAAI,CAACW,GAAG,EAAE;UAAE;MAAS;MAE/BD,EAAE,GAAGf,IAAI,CAAC1B,IAAI,CAACO,OAAO,EAAEoB,CAAC,CAAC;IAC9B,CAAC,CAAC,OAAOR,CAAC,EAAE;MAAEsB,EAAE,GAAG,CAAC,CAAC,EAAEtB,CAAC,CAAC;MAAEe,CAAC,GAAG,CAAC;IAAE,CAAC,SAAS;MAAED,CAAC,GAAGH,CAAC,GAAG,CAAC;IAAE;IACzD,IAAIW,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,MAAMA,EAAE,CAAC,CAAC,CAAC;IAAE,OAAO;MAAE7B,KAAK,EAAE6B,EAAE,CAAC,CAAC,CAAC,GAAGA,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;MAAEnB,IAAI,EAAE;IAAK,CAAC;EACpF;AACJ,CAAC;AACD7B,MAAM,CAACoD,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAElC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DkC,OAAO,CAACC,WAAW,GAAGD,OAAO,CAACE,mBAAmB,GAAGF,OAAO,CAACG,uBAAuB,GAAGH,OAAO,CAACI,wBAAwB,GAAGJ,OAAO,CAACK,aAAa,GAAGL,OAAO,CAACM,iBAAiB,GAAG,KAAK,CAAC;AACnL,IAAIC,MAAM,GAAGC,OAAO,CAAC,kBAAkB,CAAC;AACxC,IAAIC,IAAI,GAAGD,OAAO,CAAC,MAAM,CAAC;AAC1B,IAAIE,WAAW,GAAGF,OAAO,CAAC,UAAU,CAAC;AACrC,IAAIG,aAAa,GAAGH,OAAO,CAAC,eAAe,CAAC;AAC5C;AACA;AACA;AACAR,OAAO,CAACM,iBAAiB,GAAG;EACxBI,WAAW,EAAEA,WAAW;EACxBE,GAAG,EAAEC,OAAO,CAACD;AACjB,CAAC;AACD;AACA;AACA;AACA,IAAIP,aAAa,GAAG,aAAe,UAAUS,MAAM,EAAE;EACjDvE,SAAS,CAAC8D,aAAa,EAAES,MAAM,CAAC;EAChC;AACJ;AACA;EACI,SAAST,aAAa,GAAG;IACrB,IAAIU,KAAK,GAAGD,MAAM,CAAC5D,IAAI,CAAC,IAAI,EAAE;MAC1B8D,YAAY,EAAE,UAAUC,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UAChF,IAAIG,OAAO,EAAEC,SAAS,EAAEC,KAAK;UAC7B,OAAOzC,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnCH,OAAO,GAAG,IAAI,CAACI,MAAM,CAACJ,OAAO;YAC7BC,SAAS,GAAG,IAAI,CAACG,MAAM,CAACH,SAAS;YACjCC,KAAK,GAAG,IAAI,CAACE,MAAM,CAACF,KAAK;YACzB,IAAIF,OAAO,IAAI,IAAI,IAAIE,KAAK,IAAI,IAAI,EAAE;cAClC,IAAI,CAACG,uBAAuB,GACxBL,OAAO,IAAI,IAAI,GAAGM,IAAI,CAACC,IAAI,CAACP,OAAO,GAAGC,SAAS,CAAC,GAAGC,KAAK;YAChE,CAAC,MACI;cACD;cACA;cACA,IAAI,CAACG,uBAAuB,GAAG,CAAC;YACpC;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLG,YAAY,EAAE,UAAUC,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACvF,OAAOpC,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnCrB,OAAO,CAACM,iBAAiB,CAACM,GAAG,CAAC,QAAQ,CAACgB,MAAM,CAACD,KAAK,GAAG,CAAC,EAAE,KAAK,CAAC,CAACC,MAAM,CAAC,IAAI,CAACN,MAAM,CAACO,MAAM,CAAC,CAAC;YAC3F,IAAI,CAACC,iBAAiB,GAAGvB,MAAM,CAACwB,IAAI,CAACC,GAAG,EAAE;YAC1C,IAAI,CAACC,mBAAmB,GAAG,IAAI;YAC/B,IAAI,CAACC,SAAS,GAAG,IAAI;YACrB,IAAI,CAACC,oBAAoB,GAAG,CAAC;YAC7B,IAAI,CAACC,aAAa,GAAGC,OAAO,CAACC,MAAM,CAACC,OAAO;YAC3C,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLC,UAAU,EAAE,UAAUC,KAAK,EAAExB,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,IAAI2B,sBAAsB,EAAEC,UAAU;UACtC,OAAOhE,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnC,QAAQA,EAAE,CAACvC,KAAK;cACZ,KAAK,CAAC;gBACF,IAAI,CAACqD,oBAAoB,EAAE;gBAC3B,IAAIM,KAAK,KAAK,CAAC,EAAE;kBACb,IAAI,CAACG,WAAW,GAAG,IAAI5C,OAAO,CAACM,iBAAiB,CAACI,WAAW,CAAC,+CAA+C,EAAE;oBAC1GmC,KAAK,EAAErB,IAAI,CAACsB,KAAK,CAAC,GAAG,GAAG,IAAI,CAACV,aAAa,CAAC;oBAC3CW,KAAK,EAAE,IAAI,CAACxB,uBAAuB,GAAG,CAAC;oBACvCyB,IAAI,EAAE,GAAG;oBACTC,cAAc,EAAE,IAAI,CAACC;kBACzB,CAAC,CAAC;gBACN;gBACAR,sBAAsB,GAAGlB,IAAI,CAACsB,KAAK,CAAC,IAAI,CAACV,aAAa,GAAG,GAAG,GAAG,EAAE,CAAC;gBAClEO,UAAU,GAAG;kBACTQ,8BAA8B,EAAE,IAAI,CAACC,0BAA0B,CAACnC,IAAI,EAAEyB,sBAAsB;gBAChG,CAAC;gBACD,IAAI,IAAI,CAACnB,uBAAuB,KAAK,CAAC,EAAE;kBACpC;kBACA,IAAI,CAACqB,WAAW,CAACS,IAAI,CAAC,CAAC,EAAEV,UAAU,CAAC;gBACxC,CAAC,MACI;kBACD,IAAI,CAACC,WAAW,CAACS,IAAI,CAACV,UAAU,CAAC;gBACrC;gBACA,OAAO,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,EAAEpC,MAAM,CAAC+C,SAAS,GAAG,CAAC;cACjD,KAAK,CAAC;gBACFjC,EAAE,CAACtC,IAAI,EAAE;gBACT,IAAI0D,KAAK,KAAK,IAAI,CAAClB,uBAAuB,GAAG,CAAC,EAAE;kBAC5C,IAAI,CAACU,mBAAmB,GAAG1B,MAAM,CAACwB,IAAI,CAACC,GAAG,EAAE,GAAG,IAAI,CAACF,iBAAiB;kBACrE,IAAI,CAACI,SAAS,GAAG,IAAI,CAACZ,MAAM,CAACJ,OAAO,IAAI,IAAI,GACxC,IAAI,CAACe,mBAAmB,GAAG,IAAI,CAACX,MAAM,CAACJ,OAAO,GAAG,GAAG,GACpD,IAAI,CAACe,mBAAmB,GAAG,IAAI,CAACE,oBAAoB,GAAG,GAAG;gBAClE;gBACA,OAAO,CAAC,CAAC,CAAC,WAAW;YAAC;UAElC,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLoB,UAAU,EAAE,UAAU5B,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,IAAIyC,sBAAsB;UAC1B,OAAO7E,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnC,QAAQA,EAAE,CAACvC,KAAK;cACZ,KAAK,CAAC;gBACF,IAAI,IAAI,CAACmD,mBAAmB,IAAI,IAAI,EAAE;kBAClC;kBACA;kBACA;kBACA,IAAI,CAACA,mBAAmB,GAAG1B,MAAM,CAACwB,IAAI,CAACC,GAAG,EAAE,GAAG,IAAI,CAACF,iBAAiB;kBACrE,IAAI,CAACI,SAAS,GACV,IAAI,CAACD,mBAAmB,GAAG,IAAI,CAACE,oBAAoB,GAAG,GAAG;gBAClE;gBACA,IAAI,CAACS,WAAW,CAACS,IAAI,CAAC;kBAAEF,8BAA8B,EAAE;gBAAG,CAAC,CAAC;gBAC7DK,sBAAsB,GAAG,IAAI,CAACJ,0BAA0B,CAACnC,IAAI,CAAC;gBAC9DjB,OAAO,CAACM,iBAAiB,CAACM,GAAG,CAAC,EAAE,CAACgB,MAAM,CAAC,IAAI,CAACK,mBAAmB,CAACwB,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,GAC/E,EAAE,CAAC7B,MAAM,CAAC,IAAI,CAACM,SAAS,CAACuB,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,GAClD,EAAE,CAAC7B,MAAM,CAAC4B,sBAAsB,CAAC,CAAC;gBACtC,OAAO,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,EAAEjD,MAAM,CAAC+C,SAAS,GAAG,CAAC;cACjD,KAAK,CAAC;gBACFjC,EAAE,CAACtC,IAAI,EAAE;gBACT,OAAO,CAAC,CAAC,CAAC,WAAW;YAAC;UAElC,CAAC,CAAC;QACN,CAAC,CAAC;MAAE;IACR,CAAC,CAAC,IAAI,IAAI;IACVgC,KAAK,CAACmC,kBAAkB,GAAG,EAAE;IAC7B,OAAOnC,KAAK;EAChB;EACAV,aAAa,CAACrD,SAAS,CAACoG,0BAA0B,GAAG,UAAUnC,IAAI,EAAEyC,gBAAgB,EAAE;IACnF,IAAIC,cAAc,GAAG,EAAE;IACvB,IAAIC,IAAI,GAAGjH,MAAM,CAACiH,IAAI,CAAC3C,IAAI,CAAC,CAAC4C,IAAI,EAAE;IACnC,KAAK,IAAIC,EAAE,GAAG,CAAC,EAAEC,MAAM,GAAGH,IAAI,EAAEE,EAAE,GAAGC,MAAM,CAAClE,MAAM,EAAEiE,EAAE,EAAE,EAAE;MACtD,IAAIE,GAAG,GAAGD,MAAM,CAACD,EAAE,CAAC;MACpB,IAAI,IAAI,CAACG,eAAe,CAACD,GAAG,CAAC,EAAE;QAC3B,IAAIlG,KAAK,GAAGmD,IAAI,CAAC+C,GAAG,CAAC;QACrBL,cAAc,IAAI,EAAE,CAAC/B,MAAM,CAACoC,GAAG,EAAE,GAAG,CAAC,CAACpC,MAAM,CAACxB,wBAAwB,CAACtC,KAAK,CAAC,EAAE,GAAG,CAAC;MACtF;IACJ;IACA,IAAI4F,gBAAgB,IAAI,IAAI,IAAIC,cAAc,CAAC9D,MAAM,GAAG6D,gBAAgB,EAAE;MACtE;MACA;MACAC,cAAc,GAAGA,cAAc,CAACO,KAAK,CAAC,CAAC,EAAER,gBAAgB,GAAG,CAAC,CAAC,GAAG,KAAK;IAC1E;IACA,OAAOC,cAAc;EACzB,CAAC;EACDtD,aAAa,CAACrD,SAAS,CAACiH,eAAe,GAAG,UAAUD,GAAG,EAAE;IACrD,OAAOA,GAAG,KAAK,OAAO,IAAIA,GAAG,KAAK,MAAM;EAC5C,CAAC;EACD,OAAO3D,aAAa;AACxB,CAAC,CAACE,MAAM,CAAC4D,cAAc,CAAE;AACzBnE,OAAO,CAACK,aAAa,GAAGA,aAAa;AACrC,IAAI+D,eAAe,GAAG,CAAC;AACvB,IAAIC,sBAAsB,GAAG,CAAC;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASjE,wBAAwB,CAACkE,CAAC,EAAE;EACjC,IAAIC,aAAa,GAAGpE,uBAAuB,CAACmE,CAAC,CAAC;EAC9C,OAAOC,aAAa,GAAGF,sBAAsB,GACzCC,CAAC,CAACE,aAAa,CAACJ,eAAe,CAAC,GAChCE,CAAC,CAACb,OAAO,CAACc,aAAa,CAAC;AAChC;AACAvE,OAAO,CAACI,wBAAwB,GAAGA,wBAAwB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,uBAAuB,CAACmE,CAAC,EAAE;EAChC,IAAI,CAACG,MAAM,CAACC,QAAQ,CAACJ,CAAC,CAAC,IAAIA,CAAC,KAAK,CAAC,IAAIA,CAAC,GAAG,CAAC,IAAIA,CAAC,GAAG,CAAC,CAAC,EAAE;IACnD,OAAOF,eAAe;EAC1B,CAAC,MACI;IACD,OAAOA,eAAe,GAAG5C,IAAI,CAACsB,KAAK,CAACtB,IAAI,CAACmD,KAAK,CAACnD,IAAI,CAACoD,GAAG,CAACN,CAAC,CAAC,CAAC,CAAC;EAChE;AACJ;AACAtE,OAAO,CAACG,uBAAuB,GAAGA,uBAAuB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,IAAID,mBAAmB,GAAG,aAAe,UAAUY,MAAM,EAAE;EACvDvE,SAAS,CAAC2D,mBAAmB,EAAEY,MAAM,CAAC;EACtC,SAASZ,mBAAmB,CAAC2E,MAAM,EAAEC,IAAI,EAAE;IACvC,IAAID,MAAM,KAAK,KAAK,CAAC,EAAE;MAAEA,MAAM,GAAG,QAAQ;IAAE;IAC5C,IAAI9D,KAAK,GAAGD,MAAM,CAAC5D,IAAI,CAAC,IAAI,EAAE;MAC1BsF,UAAU,EAAE,UAAUC,KAAK,EAAExB,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,OAAOpC,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnC,IAAI,CAAC0D,WAAW,EAAE;YAClB,IAAI,IAAI,CAACD,IAAI,CAACE,UAAU,KAAK,OAAO,EAAE;cAClC,IAAI,CAACC,UAAU,CAAChE,IAAI,EAAE,QAAQ,EAAE,IAAI,CAAC8D,WAAW,CAAC;YACrD;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLxB,UAAU,EAAE,UAAU5B,KAAK,EAAEV,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UACrF,OAAOpC,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnC,IAAI,CAAC4D,UAAU,CAAChE,IAAI,EAAE,QAAQ,EAAEU,KAAK,GAAG,CAAC,CAAC;YAC1C,IAAI,IAAI,CAACmD,IAAI,CAACI,aAAa,GAAG,CAAC,IAC3BvD,KAAK,GAAG,IAAI,CAACmD,IAAI,CAACI,aAAa,KAAK,CAAC,EAAE;cACvC,IAAI,CAACC,UAAU,CAACxD,KAAK,CAAC;YAC1B;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE,CAAC;;MACLyD,UAAU,EAAE,UAAUnE,IAAI,EAAE;QAAE,OAAOzD,SAAS,CAACuD,KAAK,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,EAAE,YAAY;UAC9E,OAAOpC,WAAW,CAAC,IAAI,EAAE,UAAU0C,EAAE,EAAE;YACnC,IAAI,IAAI,CAACgE,WAAW,IAAI,IAAI,EAAE;cAC1B,IAAI,CAACA,WAAW,CAACC,KAAK,EAAE;YAC5B;YACA,IAAI,IAAI,CAACC,SAAS,IAAI,IAAI,EAAE;cACxB,IAAI,CAACA,SAAS,CAACD,KAAK,EAAE;YAC1B;YACA,OAAO,CAAC,CAAC,CAAC,WAAW;UACzB,CAAC,CAAC;QACN,CAAC,CAAC;MAAE;IACR,CAAC,CAAC,IAAI,IAAI;IACVvE,KAAK,CAAC8D,MAAM,GAAGA,MAAM;IACrB9D,KAAK,CAACyE,KAAK,GAAG,IAAI;IAClBzE,KAAK,CAAC+D,IAAI,GAAGA,IAAI,IAAI,IAAI,GAAG,CAAC,CAAC,GAAGA,IAAI;IACrC,IAAI/D,KAAK,CAAC+D,IAAI,CAACE,UAAU,IAAI,IAAI,EAAE;MAC/BjE,KAAK,CAAC+D,IAAI,CAACE,UAAU,GAAG,OAAO;IACnC;IACAzE,MAAM,CAACwB,IAAI,CAAC0D,MAAM,CAAC,CAAC,OAAO,EAAE,OAAO,CAAC,CAACC,OAAO,CAAC3E,KAAK,CAAC+D,IAAI,CAACE,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,YAAY;MAAE,OAAO,wDAAwD,GACtJ,EAAE,CAACpD,MAAM,CAACb,KAAK,CAAC+D,IAAI,CAACE,UAAU,CAAC;IAAE,CAAC,CAAC;IACxC,IAAIjE,KAAK,CAAC+D,IAAI,CAACI,aAAa,IAAI,IAAI,EAAE;MAClCnE,KAAK,CAAC+D,IAAI,CAACI,aAAa,GAAG,CAAC;IAChC;IACA3E,MAAM,CAACwB,IAAI,CAAC0D,MAAM,CAAChB,MAAM,CAACkB,SAAS,CAAC5E,KAAK,CAAC+D,IAAI,CAACI,aAAa,CAAC,IACzDnE,KAAK,CAAC+D,IAAI,CAACI,aAAa,IAAI,CAAC,EAAE,YAAY;MAAE,OAAO,2DAA2D,GAC/G,EAAE,CAACtD,MAAM,CAACb,KAAK,CAAC+D,IAAI,CAACI,aAAa,CAAC;IAAE,CAAC,CAAC;IAC3CnE,KAAK,CAACgE,WAAW,GAAG,CAAC;IACrB,OAAOhE,KAAK;EAChB;EACAb,mBAAmB,CAAClD,SAAS,CAAC4I,QAAQ,GAAG,UAAUJ,KAAK,EAAE;IACtD;IACA;IACA;IACA;IACA;IACA,IAAI,CAACA,KAAK,GAAGA,KAAK;EACtB,CAAC;EACDtF,mBAAmB,CAAClD,SAAS,CAACiI,UAAU,GAAG,UAAUhE,IAAI,EAAE4E,MAAM,EAAE1H,IAAI,EAAE;IACrE,KAAK,IAAI6F,GAAG,IAAI/C,IAAI,EAAE;MAClB,IAAI+C,GAAG,KAAK,OAAO,IAAIA,GAAG,KAAK,MAAM,IAAIA,GAAG,KAAK,WAAW,EAAE;QAC1D;MACJ;MACA,IAAI8B,UAAU,GAAG,MAAM;MACvB,IAAI9B,GAAG,CAAC+B,UAAU,CAACD,UAAU,CAAC,EAAE;QAC5B,IAAI,CAACE,sBAAsB,EAAE;QAC7B,IAAIC,UAAU,GAAGJ,MAAM,GAAG7B,GAAG,CAACE,KAAK,CAAC4B,UAAU,CAACjG,MAAM,CAAC;QACtD,IAAI,CAAC0F,SAAS,CAACW,MAAM,CAACD,UAAU,EAAEhF,IAAI,CAAC+C,GAAG,CAAC,EAAE7F,IAAI,CAAC;MACtD,CAAC,MACI;QACD,IAAI,CAACgI,wBAAwB,EAAE;QAC/B,IAAI,CAACd,WAAW,CAACa,MAAM,CAAC,EAAE,CAACtE,MAAM,CAACiE,MAAM,CAAC,CAACjE,MAAM,CAACoC,GAAG,CAAC,EAAE/C,IAAI,CAAC+C,GAAG,CAAC,EAAE7F,IAAI,CAAC;MAC3E;IACJ;EACJ,CAAC;EACD+B,mBAAmB,CAAClD,SAAS,CAACmI,UAAU,GAAG,UAAUhH,IAAI,EAAE;IACvD,KAAK,IAAI2F,EAAE,GAAG,CAAC,EAAEzC,EAAE,GAAG,IAAI,CAACmE,KAAK,CAACY,OAAO,EAAEtC,EAAE,GAAGzC,EAAE,CAACxB,MAAM,EAAEiE,EAAE,EAAE,EAAE;MAC5D,IAAIsC,OAAO,GAAG/E,EAAE,CAACyC,EAAE,CAAC;MACpB,IAAI,CAACuB,WAAW,CAACgB,SAAS,CAACD,OAAO,CAACE,IAAI,EAAEF,OAAO,CAACG,IAAI,EAAE,EAAEpI,IAAI,CAAC;IAClE;EACJ,CAAC;EACD+B,mBAAmB,CAAClD,SAAS,CAACmJ,wBAAwB,GAAG,YAAY;IACjE,IAAI,CAACd,WAAW,GAAG,CAAC,CAAC,EAAE1E,aAAa,CAAC6F,iBAAiB,EAAE/F,IAAI,CAACgG,IAAI,CAAC,IAAI,CAAC5B,MAAM,EAAE,OAAO,CAAC,CAAC;EAC5F,CAAC;EACD3E,mBAAmB,CAAClD,SAAS,CAACgJ,sBAAsB,GAAG,YAAY;IAC/D,IAAI,CAACT,SAAS,GAAG,CAAC,CAAC,EAAE5E,aAAa,CAAC6F,iBAAiB,EAAE/F,IAAI,CAACgG,IAAI,CAAC,IAAI,CAAC5B,MAAM,EAAE,KAAK,CAAC,CAAC;EACxF,CAAC;EACD,OAAO3E,mBAAmB;AAC9B,CAAC,CAACK,MAAM,CAAC4D,cAAc,CAAE;AACzBnE,OAAO,CAACE,mBAAmB,GAAGA,mBAAmB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,WAAW,CAAC4E,MAAM,EAAEC,IAAI,EAAE;EAC/B,IAAID,MAAM,KAAK,KAAK,CAAC,EAAE;IAAEA,MAAM,GAAG,QAAQ;EAAE;EAC5C,OAAO,IAAI3E,mBAAmB,CAAC2E,MAAM,EAAEC,IAAI,CAAC;AAChD;AACA9E,OAAO,CAACC,WAAW,GAAGA,WAAW"},"metadata":{},"sourceType":"script","externalDependencies":[]}